{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.torch_basics import *\n",
    "from local.test import *\n",
    "from local.data.all import *\n",
    "from local.vision.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/quantran/.fastai/data/mnist_tiny/train/7/9286.png')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = untar_data(URLs.MNIST_TINY)/'train'\n",
    "items = get_image_files(source)\n",
    "fn = items[0]\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(array(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg(x): return -x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-74b13307e3f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-e69650f4afb8>\u001b[0m in \u001b[0;36mneg\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary -: 'tuple'"
     ]
    }
   ],
   "source": [
    "neg((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg(array((1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform decorator can make a function work in a flexible way (inputs with different type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def neg(x): return -x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This @Transform looks like you gonna pass the func (neg) in ```__init__``` of class Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent\n",
    "def _neg(x): return -x\n",
    "neg = Transform(_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, -2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg((1,2)) # this is like calling encode function in Transform class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmElEQVR4nGNgGDaAEcbwUrvpLsxocmP5SiyqCv79+3X8xPFH7wWwSJb/c1ZkYGAw+ueBEGOCMXQYHt5nYGD4jKyBiQEPgEsyfvzGwMDAYP1uBxZVPPoMDAwMDJtf4zaI4/493Hbqy28i2UEwdzHikfx/Bp+xN3FLquOz0xifJIp70CVX/8cj+YtBD7ckA4MOHsnPa9FV4wIAY6Uh9HUz4SgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F56ADCA1B50>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_image(fn)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0, 164, 239,  26,   0,   0,   0,\n",
       "           0,  96, 236,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  12,  47,   0,   0,   0,   0,\n",
       "           0, 179, 235,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tensor(array(img))\n",
    "t[12:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,  92,  17, 230,   0,   0,   0,\n",
       "           0, 160,  20,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0, 244, 209,   0,   0,   0,   0,\n",
       "           0,  77,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg(t[12:14]) # negative here doesn't really work, due to type uint8 doesn't allow negative number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0., -164., -239.,\n",
       "          -26.,   -0.,   -0.,   -0.,   -0.,  -96., -236.,   -0.,   -0.,   -0.,\n",
       "           -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.],\n",
       "        [  -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,  -12.,  -47.,\n",
       "           -0.,   -0.,   -0.,   -0.,   -0., -179., -235.,   -0.,   -0.,   -0.,\n",
       "           -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = t.float()\n",
    "neg(t2[12:14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization, type notation to work with tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x,m,s): return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0, 164, 239,  26,   0,   0,   0,\n",
       "           0,  96, 236,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  12,  47,   0,   0,   0,   0,\n",
       "           0, 179, 235,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[12:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t2 # to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_img = norm(t,127,50)\n",
    "n_img[12:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.2250)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_img.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def norm(x,m,s): return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "           0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "           2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "           2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "           1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400]]), -2.52)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tupl = (t,1) # assume a image t with label '1'\n",
    "temp = norm(tupl,m=127,s=50) # need keywords for @Transform norm\n",
    "temp[0][12:15],temp[1] # but we don't want label to get transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def norm(x:torch.Tensor,m,s): return (x-m)/s #type notation added: determine which of the tuple to apply tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "           0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "           2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "           2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "           1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400]]), 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = norm(tupl,m=127,s=50)\n",
    "temp[0][12:15],temp[1] # fixed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic markers to existing type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??TensorBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTensorImg(TensorBase): pass # Note: why this extra step\n",
    "# fastai wants to add 'semantic markers' to original type to represent 'different kinds of information' (such as to show using show()),\n",
    "# aside from what the original type has to offer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_t = MyTensorImg(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.MyTensorImg, torch.Tensor)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_t),type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(t,m=127,s=50)[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(my_t,m=127,s=50)[12:15] # still works, as type notation will allow children of the type specified in the func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def norm2(x:MyTensorImg,m,s): return (x-m)/s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 164., 239.,  26.,   0.,\n",
       "           0.,   0.,   0.,  96., 236.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  12.,  47.,   0.,   0.,\n",
       "           0.,   0.,   0., 179., 235.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   8., 223., 222.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm2(t,m=127,s=50)[12:15] # not working, since torch.Tensor is not the same or children of MyTensorImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm2(my_t,m=127,s=50)[12:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inherit from Transform (to keep a state/attribute for your transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to 'encode'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(Transform):\n",
    "    def __init__(self,m,s):\n",
    "        super().__init__()\n",
    "#         store_attr(self,'m,s')\n",
    "        self.m,self.s = m,s\n",
    "    def encodes(self,x:torch.Tensor): return (x-self.m)/self.s\n",
    "    def encodes(self,x: MyTensorImg): return (x-self.m)/self.s\n",
    "    # add other type for encodes here if you want\n",
    "    \n",
    "    def decodes(self,x: MyTensorImg): return (x*self.s)+ self.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent, dynamically. TODO: need testing, since\n",
    "\n",
    "# class Norm(Transform): pass\n",
    "\n",
    "# @Norm\n",
    "# def encodes(self,x:torch.Tensor,m,s): return (x-m)/s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.MyTensorImg, torch.Tensor)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_t),type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = Norm(m=127,s=50)\n",
    "f(my_t)[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(t)[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_t_norm = f(my_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000, 164.0000, 239.0000,  26.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,  96.0000, 236.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,  12.0000,  47.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000, 179.0000, 235.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           8.0000, 223.0000, 222.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.decodes(my_t_norm)[12:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple transform in one go = Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## option 1: use compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(9).view(3,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 0],\n",
       "        [5, 4, 3],\n",
       "        [8, 7, 6]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flip(x,[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def flip_img(x:MyTensorImg): return torch.flip(x,[1]) # flip among axis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_norm =Norm(m=127,s=50)\n",
    "f_compose = compose(f_norm,flip_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.MyTensorImg"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = f_compose(my_t)\n",
    "type(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400,  2.1800, -0.6200, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.0200,  2.2400,  0.7400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400,  2.1600,  1.0400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -1.6000, -2.3000, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400,  1.9000,  1.9200, -2.3800, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-cbfda337d5f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# but no decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf_compose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "# but no decode\n",
    "f_compose.decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## option 2: use pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that Pipeline will convert everything into Transform, so no need for Transform annotation like in option 1\n",
    "\n",
    "# @Transform: this is no need\n",
    "def flip_img(x:MyTensorImg): return torch.flip(x,[1]) # flip among axis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_norm =Norm(m=127,s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400,  2.1800, -0.6200, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.0200,  2.2400,  0.7400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400,  2.1600,  1.0400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -1.6000, -2.3000, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400,  1.9000,  1.9200, -2.3800, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Pipeline([f_norm,flip_img])\n",
    "temp = p(my_t)\n",
    "temp[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.MyTensorImg"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(temp) # Note that it keeps the original type, even though flip_img should technically output a torch tensor due to torch,flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.MyTensorImg"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(p.decode(temp)) # decode keeps the original type too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000, 236.0000,  96.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,  26.0000, 239.0000, 164.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000, 235.0000, 179.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,  47.0000,  12.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000, 222.0000, 223.0000,   8.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.decode(temp)[12:15] # note that only f_norm decode is called. flip_img does not have decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.MyTensorImg"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_t_tuple = (my_t,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400,  2.1800, -0.6200, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.0200,  2.2400,  0.7400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400,  2.1600,  1.0400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -1.6000, -2.3000, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400,  1.9000,  1.9200, -2.3800, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400]]), 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Pipeline([f_norm,flip_img])\n",
    "temp = p(my_t_tuple)\n",
    "temp[0][12:15],temp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 164., 239.,  26.,   0.,\n",
       "            0.,   0.,   0.,  96., 236.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  12.,  47.,   0.,   0.,\n",
       "            0.,   0.,   0., 179., 235.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   8., 223., 222.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.]]), 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Pipeline([f_norm,flip_img],as_item=True) # note again: as_item=True will force the input as a whole object. So this object is gonna be type 'Tuple'\n",
    "temp = p(my_t_tuple)\n",
    "temp[0][12:15],temp[1] #there is no encode(...,o:Tuple), so no transformation is performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify output of function (not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def create_image_tensor(x): return tensor(array(load_image(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/quantran/.fastai/data/mnist_tiny/train/7/9286.png')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = create_image_tensor(fn)\n",
    "type(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify/cast output type (NOT WORKING NOW)\n",
    "@Transform\n",
    "def create_image_tensor(x)->TensorImage: return tensor(array(load_image(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = create_image_tensor(fn)\n",
    "type(temp) #TODO: that does not work... it should return local.torch_core.TensorImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "local.torch_core.TensorImage"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metaclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my own note: https://colab.research.google.com/drive/1FN8JmmY7nr0fHJ4bTkTOYOrkGQzhKyyB#scrollTo=VS4D0EoBKJVS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type: a class to construct other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(type, __main__.Foo)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Foo(object): \n",
    "    a=1\n",
    "type(Foo),type(Foo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': '__main__',\n",
       "              'a': 1,\n",
       "              '__dict__': <attribute '__dict__' of 'Foo' objects>,\n",
       "              '__weakref__': <attribute '__weakref__' of 'Foo' objects>,\n",
       "              '__doc__': None})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Foo.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(type, __main__.Foo)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# equivalent\n",
    "Foo = type('Foo',(object,),{'a':1})\n",
    "type(Foo),type(Foo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'a': 1,\n",
       "              '__module__': '__main__',\n",
       "              '__dict__': <attribute '__dict__' of 'Foo' objects>,\n",
       "              '__weakref__': <attribute '__weakref__' of 'Foo' objects>,\n",
       "              '__doc__': None})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Foo.__dict__ # notice that in both cases, the class attribute 'a' is stored in __dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that Foo will inherit every function in type, because it's a 'type' type. Try to do Foo._ and tab for autocompletion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your own 'type': a class to construct other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _M(type):\n",
    "    def __new__(cls,name,bases,dict):\n",
    "        print('__new__ in _M')\n",
    "        return super().__new__(cls,name,bases,dict)\n",
    "    \n",
    "    @classmethod\n",
    "    def __prepare__(cls,name,bases): return {'a':1} \n",
    "    # to add class attributes to anything constructed by this _M (will be shown in __dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__new__ in _M\n"
     ]
    }
   ],
   "source": [
    "class T(metaclass= _M): # construct class T using _M as a metaclass\n",
    "    def some_func(self): return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'a': 1,\n",
       "              '__module__': '__main__',\n",
       "              'some_func': <function __main__.T.some_func(self)>,\n",
       "              '__dict__': <attribute '__dict__' of 'T' objects>,\n",
       "              '__weakref__': <attribute '__weakref__' of 'T' objects>,\n",
       "              '__doc__': None})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.T.some_func(self)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.some_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.T object at 0x7fada9a6e510>\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "temp = T()\n",
    "print(temp)\n",
    "print(temp.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metaclass of Transform: _TfmMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm_methods = 'encodes','decodes','setups'\n",
    "\n",
    "class _TfmDict(dict):\n",
    "    def __setitem__(self,k,v):\n",
    "        if k not in _tfm_methods or not callable(v): return super().__setitem__(k,v) # if not encodes, decodes or setups, act like a normal dict\n",
    "        if k not in self: super().__setitem__(k,TypeDispatch()) #if self does not already have 1 of those 3, create one and set it to TypeDispatch (?)\n",
    "        self[k].add(v)\n",
    "\n",
    "class _TfmMeta(type):\n",
    "    def __new__(cls, name, bases, dict): \n",
    "        # this is called when only definition of class is created, not when an instance of that class is created\n",
    "        # i.e. when you do class Transform(metaclass=_TfmMeta): pass \n",
    "        res = super().__new__(cls, name, bases, dict)\n",
    "        res.__signature__ = inspect.signature(res.__init__)\n",
    "        return res\n",
    "\n",
    "    def __call__(cls, *args, **kwargs):\n",
    "        f = args[0] if args else None\n",
    "        n = getattr(f,'__name__',None)\n",
    "        for nm in _tfm_methods:\n",
    "            if not hasattr(cls,nm): setattr(cls, nm, TypeDispatch())\n",
    "        if callable(f) and n in _tfm_methods:\n",
    "            getattr(cls,n).add(f)\n",
    "            return f\n",
    "        return super().__call__(*args, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def __prepare__(cls, name, bases): return _TfmDict() \n",
    "    #set TypeDispatch for special 3 functions. This will achieve 'TypeAnnotation' behavior in fastai v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(metaclass=_TfmMeta):\n",
    "    def encodes(self,x): return x\n",
    "    def encodes(self,x:int): return x\n",
    "    def encodes(self,x:float): return x\n",
    "    def sum_func(self): return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': '__main__', 'encodes': (float,object) -> encodes\n",
       "              (int,object) -> encodes\n",
       "              (object,object) -> encodes, 'sum_func': <function __main__.A.sum_func(self)>, '__dict__': <attribute '__dict__' of 'A' objects>, '__weakref__': <attribute '__weakref__' of 'A' objects>, '__doc__': None, '__signature__': <Signature (self, /, *args, **kwargs)>})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(float,object) -> encodes\n",
       "(int,object) -> encodes\n",
       "(object,object) -> encodes"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.encodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "local.core.dispatch.TypeDispatch"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(A.encodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function __main__.A.sum_func(self)>, function)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum_func,type(A.sum_func) # not 1 of those 3 things, so behave normally"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
