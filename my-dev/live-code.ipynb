{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.torch_basics import *\n",
    "from local.test import *\n",
    "from local.data.all import *\n",
    "from local.vision.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/quantran/.fastai/data/mnist_tiny/train/7/9286.png')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = untar_data(URLs.MNIST_TINY)/'train'\n",
    "items = get_image_files(source)\n",
    "fn = items[0]\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(array(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg(x): return -x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-74b13307e3f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-e69650f4afb8>\u001b[0m in \u001b[0;36mneg\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary -: 'tuple'"
     ]
    }
   ],
   "source": [
    "neg((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg(array((1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform decorator can make a function work in a flexible way (inputs with different type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def neg(x): return -x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This @Transform just mean that you gonna pass the func (neg) in ```__init__``` of class Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent\n",
    "def _neg(x): return -x\n",
    "neg = Transform(_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, -2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmElEQVR4nGNgGDaAEcbwUrvpLsxocmP5SiyqCv79+3X8xPFH7wWwSJb/c1ZkYGAw+ueBEGOCMXQYHt5nYGD4jKyBiQEPgEsyfvzGwMDAYP1uBxZVPPoMDAwMDJtf4zaI4/493Hbqy28i2UEwdzHikfx/Bp+xN3FLquOz0xifJIp70CVX/8cj+YtBD7ckA4MOHsnPa9FV4wIAY6Uh9HUz4SgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FC35B8E94D0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_image(fn)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0, 164, 239,  26,   0,   0,   0,\n",
       "           0,  96, 236,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  12,  47,   0,   0,   0,   0,\n",
       "           0, 179, 235,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tensor(array(img))\n",
    "t[12:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,  92,  17, 230,   0,   0,   0,\n",
       "           0, 160,  20,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0, 244, 209,   0,   0,   0,   0,\n",
       "           0,  77,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg(t[12:14]) # negative here doesn't really work, due to type uint8 doesn't allow negative number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0., -164., -239.,\n",
       "          -26.,   -0.,   -0.,   -0.,   -0.,  -96., -236.,   -0.,   -0.,   -0.,\n",
       "           -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.],\n",
       "        [  -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,  -12.,  -47.,\n",
       "           -0.,   -0.,   -0.,   -0.,   -0., -179., -235.,   -0.,   -0.,   -0.,\n",
       "           -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = t.float()\n",
    "neg(t2[12:14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization, type notation to work with tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x,m,s): return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0, 164, 239,  26,   0,   0,   0,\n",
       "           0,  96, 236,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  12,  47,   0,   0,   0,   0,\n",
       "           0, 179, 235,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[12:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_img = norm(t,127,50)\n",
    "n_img[12:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.2250)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_img.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def norm(x,m,s): return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "           0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "           2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "           2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "           1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400]]), -2.52)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tupl = (t,1) # assume a image t with label '1'\n",
    "temp = norm(tupl,m=127,s=50)\n",
    "temp[0][12:15],temp[1] # but we don't want label to get transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def norm(x:torch.Tensor,m,s): return (x-m)/s #type notation added: determine which of the tuple to apply tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "           0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "           2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "           2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "           1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400]]), 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = norm(tupl,m=127,s=50)\n",
    "temp[0][12:15],temp[1] # fixed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic markers to existing type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??TensorBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTensorImg(TensorBase): pass # Note: why this extra step\n",
    "# fastai wants to add 'semantic markers' to original type to represent 'different kinds of information' (such as to show using show()),\n",
    "# aside from what the original type has to offer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_t = MyTensorImg(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.MyTensorImg, torch.Tensor)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_t),type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(t,m=127,s=50)[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(my_t,m=127,s=50)[12:15] # still works, as type notation will allow children of the type specified in the func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def norm2(x:MyTensorImg,m,s): return (x-m)/s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 164., 239.,  26.,   0.,\n",
       "           0.,   0.,   0.,  96., 236.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  12.,  47.,   0.,   0.,\n",
       "           0.,   0.,   0., 179., 235.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   8., 223., 222.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm2(t,m=127,s=50)[12:15] # not working, since torch.Tensor is not the same or children of MyTensorImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm2(my_t,m=127,s=50)[12:15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
