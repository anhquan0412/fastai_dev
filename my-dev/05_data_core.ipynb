{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.torch_basics import *\n",
    "from local.test import *\n",
    "from local.data.load import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.notebook.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data core\n",
    "\n",
    "> Core functionality for gathering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes here provide functionality for applying a list of transforms to a set of items (`TfmdList`, `DataSource`) or a `DataLoader` (`TfmdDl`) as well as the base class used to gatehr the data for model training: `DataBunch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdDL -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_show_batch(x, y, its, ctxs=None, max_n=10, **kwargs):\n",
    "    if ctxs is None: ctxs = Inf.nones\n",
    "    for i in range(1 if y is None else 2):\n",
    "        ctxs = [b.show(ctx=c, **kwargs) for b,c,_ in zip(its.itemgot(i),ctxs,range(max_n))]\n",
    "    return ctxs\n",
    "def default_show_results(x, y, its, ctxs=None, max_n=10, **kwargs):\n",
    "    if ctxs is None: ctxs = Inf.nones\n",
    "    for i in range(3):\n",
    "        ctxs = [b.show(ctx=c, **kwargs) for b,c,_ in zip(its.itemgot(i),ctxs,range(max_n))]\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typedispatch\n",
    "def show_batch(*args, **kwargs): return default_show_batch(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typedispatch\n",
    "def show_results(*args, **kwargs): return default_show_results(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_all_ = [\"show_batch\", \"show_results\"]\n",
    "_batch_tfms = ('after_item','before_batch','after_batch') # list specific callbacks for transform pipeline\n",
    "# 'after_item': after grabing a single item in dataset. \n",
    "# 'before_batch': after getting all items together, but right before collating them into batch (the only one that will be done as individual item (as_item=True). The rest will be done as Tuple Transform)\n",
    "# See 08_pets notebook to know what these are specifically\n",
    "# 'after_batch': after collating into a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old friend compose. This compose is a function though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates() #Note: this decorator will replace the **kwargs with argument names of its parent class (DataLoader) when you shift tab, and help autocompletion\n",
    "class TfmdDL(DataLoader):\n",
    "    \"Transformed `DataLoader`\"\n",
    "    def __init__(self, dataset, bs=16, shuffle=False, num_workers=None, **kwargs):\n",
    "        if num_workers is None: num_workers = min(16, defaults.cpus)\n",
    "        for nm in _batch_tfms:\n",
    "            kwargs[nm] = Pipeline(kwargs.get(nm,None), as_item=(nm=='before_batch')) # Turn them into pipeline here, set 'before_batch' as item transform\n",
    "            kwargs[nm].setup(self)\n",
    "        super().__init__(dataset, bs=bs, shuffle=shuffle, num_workers=num_workers, **kwargs)\n",
    "\n",
    "    def _one_pass(self):\n",
    "        its = self.after_batch(self.do_batch([self.do_item(0)]))\n",
    "        self._device = find_device(its)\n",
    "        self._n_inp = 1 if not isinstance(its, (list,tuple)) or len(its)==1 else len(its)-1\n",
    "        self._retain_dl = partial(retain_types, typs=mapped(type,its)) # to retain the original type of data at the end of the batch\n",
    "        \n",
    "    def _retain_dl(self,b):\n",
    "        self._one_pass()\n",
    "        # we just replaced ourselves, so this is *not* recursive! :)\n",
    "        return self._retain_dl(b)\n",
    "\n",
    "    def before_iter(self):\n",
    "        super().before_iter()\n",
    "        split_idx = getattr(self.dataset, 'split_idx', None)\n",
    "        for nm in _batch_tfms:\n",
    "            f = getattr(self,nm)\n",
    "            if isinstance(f,Pipeline): f.split_idx=split_idx\n",
    "\n",
    "    def decode(self, b): return self.before_batch.decode(self.after_batch.decode(self._retain_dl(b)))\n",
    "    def decode_batch(self, b, max_n=10, full=True): return self._decode_batch(self.decode(b), max_n, full)\n",
    "\n",
    "    def _decode_batch(self, b, max_n=10, full=True):\n",
    "        f = self.after_item.decode\n",
    "        f = compose(f, partial(getattr(self.dataset,'decode',noop), full = full)) \n",
    "        #old friend compose. This compose is a function though (see below)\n",
    "        return L(batch_to_samples(b, max_n=max_n)).map(f)\n",
    "\n",
    "    def _pre_show_batch(self, b, max_n=10, **kwargs):\n",
    "        b = self.decode(b)\n",
    "        if hasattr(b, 'show'): return b,None,None\n",
    "        its = self._decode_batch(b, max_n, full=False)\n",
    "        if not is_listy(b): b,its = [b],L((o,) for o in its)\n",
    "        return detuplify(b[:self.n_inp]),detuplify(b[self.n_inp:]),its\n",
    "        \n",
    "    def show_batch(self, b=None, max_n=10, ctxs=None, **kwargs):\n",
    "        \"Show `b` (defaults to `one_batch`), a list of lists of pipeline outputs (i.e. output of a `DataLoader`)\"\n",
    "        '''\n",
    "        1. pass in some batch to show\n",
    "        2. decode that batch (using after batch and before batch transform): before_batch.decode and after_batch.decode\n",
    "        3. context: can be from matplotlib (axes) or pandas dataframe. Can be fetched from the type of the obj in the batch\n",
    "        4. Call .show()\n",
    "        '''\n",
    "        if b is None: b = self.one_batch()\n",
    "        show_batch(*self._pre_show_batch(b, max_n=max_n, **kwargs), ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "    \n",
    "    def show_results(self, b, out, max_n=10, ctxs=None, **kwargs):\n",
    "        x,y,its = self._pre_show_batch(b, max_n=max_n, **kwargs)\n",
    "        b_out = b[:self.n_inp] + (tuple(out) if is_listy(out) else (out,))\n",
    "        x1,y1,outs = self._pre_show_batch(b_out, max_n=max_n, **kwargs)\n",
    "        if its is not None: \n",
    "            its = L(i + o[self.n_inp:] for i,o in zip(its,outs))\n",
    "            show_results(x, y, its, ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "        #its None means that a batch knos how to show itself as a whole, so we pass x, x1\n",
    "        else: show_results(x, x1, its, ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "            \n",
    "    @property\n",
    "    def device(self):\n",
    "        if not hasattr(self, '_device'): _ = self._one_pass()\n",
    "        return self._device\n",
    "    \n",
    "    @property\n",
    "    def n_inp(self): \n",
    "        if hasattr(self.dataset, 'n_inp'): return self.dataset.n_inp\n",
    "        if not hasattr(self, '_n_inp'): self._one_pass()\n",
    "        return self._n_inp\n",
    "    \n",
    "    @property\n",
    "    def items(self): return self.tls[0].items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def compose(*funcs, order=None):\n",
    "    \"Create a function that composes all functions in `funcs`, passing along remaining `*args` and `**kwargs` to all\"\n",
    "    funcs = L(funcs)\n",
    "    if order is not None: funcs = funcs.sorted(order)\n",
    "    def _inner(x, *args, **kwargs):\n",
    "        for f in L(funcs): x = f(x, *args, **kwargs)\n",
    "        return x\n",
    "    return _inner\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TfmdDL(\n",
    "    dataset,\n",
    "    bs=16,\n",
    "    shuffle=False,\n",
    "    num_workers=None,\n",
    "    drop_last=False,\n",
    "    indexed=None,\n",
    "    pin_memory=False,\n",
    "    timeout=0,\n",
    "    *,\n",
    "    wif=None,\n",
    "    before_iter=None,\n",
    "    create_batches=None,\n",
    "    sampler=None,\n",
    "    create_item=None,\n",
    "    after_item=None,\n",
    "    before_batch=None,\n",
    "    create_batch=None,\n",
    "    retain=None,\n",
    "    after_batch=None,\n",
    "    after_iter=None,\n",
    "    get_idxs=None,\n",
    ")\n",
    "\n",
    "DataLoader(\n",
    "    dataset=None,\n",
    "    bs=None,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    indexed=None,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    timeout=0,\n",
    "    *,\n",
    "    wif=None,\n",
    "    before_iter=None,\n",
    "    create_batches=None,\n",
    "    sampler=None,\n",
    "    create_item=None,\n",
    "    after_item=None,\n",
    "    before_batch=None,\n",
    "    create_batch=None,\n",
    "    retain=None,\n",
    "    after_batch=None,\n",
    "    after_iter=None,\n",
    "    get_idxs=None,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `TfmdDL` is a `DataLoader` that creates `Pipeline` from a list of `Transform`s for the callbacks `after_item`, `before_batch` and `after_batch`. As a result, it can decode or show a processed `batch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(TfmdDL,\n",
    "         decode=\"Decode `b` using `tfms`\",\n",
    "         decode_batch=\"Decode `b` entirely\",\n",
    "         show_batch=\"Show each item of `b`\",\n",
    "         show_results=\"Show each item of `b` and `out`\",\n",
    "         before_iter=\"override\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Category(int, ShowTitle): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([1]),), (tensor([1]),), (tensor([1]),), (tensor([1]),)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(TensorImage([1]),)] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test retain type\n",
    "class NegTfm(Transform):\n",
    "    def encodes(self, x): return torch.neg(x)\n",
    "    def decodes(self, x): return torch.neg(x)\n",
    "    \n",
    "tdl = TfmdDL([(TensorImage([1]),)] * 4, after_batch=NegTfm(), bs=4, num_workers=4)\n",
    "b = tdl.one_batch()\n",
    "test_eq(type(b[0]), TensorImage)\n",
    "# even though NegTfn.encode will return a torch.Tensor (bc of torch.neg), type is still reserved (TensorImage)\n",
    "# Note: this only works if the output is the parent class of the input (TensorImage is the subclass of torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(type(tdl.decode_batch(b)[0][0]), TensorImage)\n",
    "b = (tensor([1.,1.,1.,1.]),)\n",
    "test_eq(type(tdl.decode_batch(b)[0][0]), TensorImage)\n",
    "# Note: Because ALL OF TRANSFORMATION PIPELINE (TfmDL) ALL CHECK - AFTER GOING THROUGH ENCODE/DECODE OF EACH TFMS - that TYPE MUST BE RESERVED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegTfm(Transform):\n",
    "    def encodes(self, x)->None: return torch.neg(x) # the '-> None' means not enforcing type consistency\n",
    "    def decodes(self, x): return torch.neg(x)\n",
    "    \n",
    "tdl = TfmdDL([(TensorImage([1]),)] * 4, after_batch=NegTfm(), bs=4, num_workers=4)\n",
    "b = tdl.one_batch()\n",
    "# test_eq(type(b[0]), TensorImage) # failed\n",
    "test_eq(type(b[0]), torch.Tensor) # don't reserve type. Type will be strictly depends on encode function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tdl.decode_batch(b)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform): \n",
    "    def encodes(self, x): return x \n",
    "    def decodes(self, x): return Int(x) \n",
    "\n",
    "@Transform\n",
    "def f(x)->None: return Tuple((x,x)) # not enforcing 'reserve input type' setting\n",
    "\n",
    "start = torch.arange(50)\n",
    "test_eq_type(f(2), Tuple((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(start[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = A()\n",
    "tdl = TfmdDL(start, after_item=lambda x: (a(x), f(x)), bs=4) \n",
    "# input: 1 single item from a, torch.Tensor type (Look at _batch_tfms create_item below for more info)\n",
    "\n",
    "# return two things: a(x) which is itself and f(x) which is Tuple type\n",
    "x,y = tdl.one_batch()\n",
    "test_eq(type(y), Tuple) # encode forward? type Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,type(x),type(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([0, 1, 2, 3]), tensor([0, 1, 2, 3])), local.core.utils.Tuple)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y,type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tdl.decode_batch((x,y)) # since bs = 4, return L list of 4\n",
    "test_eq(type(s[0][1]), Tuple) # decode back? same type: Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [(tensor(0), (tensor(0), tensor(0))),(tensor(1), (tensor(1), tensor(1))),(tensor(2), (tensor(2), tensor(2))),(tensor(3), (tensor(3), tensor(3)))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdl = TfmdDL(torch.arange(0,50), after_item=A(), after_batch=NegTfm(), bs=4)\n",
    "test_eq(tdl.dataset[0], start[0])\n",
    "test_eq(len(tdl), (50-1)//4+1)\n",
    "test_eq(tdl.bs, 4)\n",
    "test_stdout(tdl.show_batch, '0\\n1\\n2\\n3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DataLoader.one_batch\" class=\"doc_header\"><code>DataLoader.one_batch</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/local/data/load.py#L99\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataLoader.one_batch</code>()\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDL.one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = NegTfm()\n",
    "tdl = TfmdDL(start, after_batch=tfm, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tdl.one_batch()\n",
    "test_eq(tensor([0,-1,-2,-3]), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TfmdDL.decode\" class=\"doc_header\"><code>TfmdDL.decode</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L29\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDL.decode</code>(**`b`**)\n",
       "\n",
       "Decode `b` using `tfms`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDL.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tdl.decode(b), tensor(0,1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TfmdDL.decode_batch\" class=\"doc_header\"><code>TfmdDL.decode_batch</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L30\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDL.decode_batch</code>(**`b`**, **`max_n`**=*`10`*, **`ds_decode`**=*`True`*)\n",
       "\n",
       "Decode `b` entirely"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDL.decode_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tdl.decode_batch(b), [0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TfmdDL.show_batch\" class=\"doc_header\"><code>TfmdDL.show_batch</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L37\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDL.show_batch</code>(**`b`**=*`None`*, **`max_n`**=*`10`*, **`ctxs`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show each item of `b`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDL.show_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataBunch -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??GetAttr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why does GetAttr this exist:\n",
    "- 1st: because the default getattr will get EVERYTHING\n",
    "\n",
    "=> get s.t with hidden error. For example a typo db.on_batch(), this will definitely be called by normal \\__getattr__ (see below to see how it is fixed)\n",
    "\n",
    "- 2nd: no tab completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "# what's going on inside add_props\n",
    "tempf1 = lambda i,x: x[i]\n",
    "tempf2 = [partial(tempf1,i) for i in range(2)]\n",
    "print(tempf2[0](['a','b']))\n",
    "print(tempf2[1](['a','b']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class DataBunch(GetAttr): \n",
    "    # GetAttr: wrapper around __getattr__, using '_default' to set what will be returned from default\n",
    "    \"Basic wrapper around several `DataLoader`s.\"\n",
    "    _default='train_dl' # _default things for tab completion\n",
    "    _xtra = 'one_batch show_batch dataset'.split() # only tab completion these things.\n",
    "    # if no _xtra, then _xtra will be set as ALL attributes inside _default\n",
    "    \n",
    "    \n",
    "    def __init__(self, *dls): self.dls = dls #note: you can pass as many dataloader as you like\n",
    "    def __getitem__(self, i): return self.dls[i]\n",
    "\n",
    "    # add_props: add property (see above)\n",
    "    # equivalent to this\n",
    "    # @property def train_dl(self): return self[0]\n",
    "    # @property def valid_dl(self): return self[1]\n",
    "    train_dl,valid_dl = add_props(lambda i,x: x[i])\n",
    "    train_ds,valid_ds = add_props(lambda i,x: x[i].dataset)\n",
    "    \n",
    "    _docs=dict(__getitem__=\"Retrieve `DataLoader` at `i` (`0` is training, `1` is validation)\",\n",
    "              train_dl=\"Training `DataLoader`\",\n",
    "              valid_dl=\"Validation `DataLoader`\",\n",
    "              train_ds=\"Training `Dataset`\",\n",
    "              valid_ds=\"Validation `Dataset`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbch = DataBunch(tdl,tdl)\n",
    "x = dbch.train_dl.one_batch() # or dbch[0].one_batch()\n",
    "x2 = next(iter(tdl))\n",
    "test_eq(x,x2)h\n",
    "x2 = dbch.one_batch() # Note: quick tab completion, result of GetAttr. This will be call one_batch from 'default' dl: train_dl\n",
    "test_eq(x,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = dbch.dataset # or this dataset will be 'default' as dbch.train_ds\n",
    "temp2 = dbch.train_ds\n",
    "test_eq(temp1,temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "on_batch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-4a2bea4eae3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdbch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/kwon/fastai_dev/my-dev/local/core/foundation.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'_xtra'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xtra\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xtra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xtra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: on_batch"
     ]
    }
   ],
   "source": [
    "dbch.on_batch() # proper behavior on typo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DataBunch.__getitem__\" class=\"doc_header\"><code>DataBunch.__getitem__</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L8\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataBunch.__getitem__</code>(**`i`**)\n",
       "\n",
       "Retrieve [`DataLoader`](/dataloader.html#DataLoader) at `i` (`0` is training, `1` is validation)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = dbch[0].one_batch()\n",
    "test_eq(x,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"train_dl\" class=\"doc_header\"><code>train_dl</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L10\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Training [`DataLoader`](/dataloader.html#DataLoader)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.train_dl, name=\"train_dl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"valid_dl\" class=\"doc_header\"><code>valid_dl</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L10\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Validation [`DataLoader`](/dataloader.html#DataLoader)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.valid_dl, name=\"valid_dl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"train_ds\" class=\"doc_header\"><code>train_ds</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L11\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Training `Dataset`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.train_ds, name=\"train_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"valid_ds\" class=\"doc_header\"><code>valid_ds</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L11\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Validation `Dataset`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.valid_ds, name=\"valid_ds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdList -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FilteredBase:\n",
    "    \"Base class for lists with subsets\"\n",
    "    _dl_type = TfmdDL\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.databunch = delegates(self._dl_type.__init__)(self.databunch)\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def _new(self, items, **kwargs): return super()._new(items, filts=self.filts, **kwargs)\n",
    "    def subset(self): raise NotImplemented\n",
    "    @property\n",
    "    def n_subsets(self): return len(self.filts)\n",
    "\n",
    "    def databunch(self, bs=16, val_bs=None, shuffle_train=True, **kwargs):\n",
    "        n = self.n_subsets-1\n",
    "        bss = [bs] + [2*bs]*n if val_bs is None else [bs] + [val_bs]*n\n",
    "        shuffles = [shuffle_train] + [False]*n\n",
    "        return DataBunch(*[self._dl_type(self.subset(i), bs=b, shuffle=s, drop_last=s, **kwargs)\n",
    "                               for i,(b,s) in enumerate(zip(bss, shuffles))])\n",
    "\n",
    "FilteredBase.train,FilteredBase.valid = add_props(lambda i,x: x.subset(i), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmdList(FilteredBase, L):\n",
    "    \"A `Pipeline` of `tfms` applied to a collection of `items`\"\n",
    "    def __init__(self, items, tfms, use_list=None, do_setup=True, as_item=True, filt=None, train_setup=True, filts=None):\n",
    "        super().__init__(items, use_list=use_list)\n",
    "        self.filts = L([slice(None)] if filts is None else filts).map(mask2idxs)\n",
    "        if isinstance(tfms,TfmdList): tfms = tfms.tfms\n",
    "        if isinstance(tfms,Pipeline): do_setup=False\n",
    "        self.tfms = Pipeline(tfms, as_item=as_item, filt=filt)\n",
    "        if do_setup: self.setup(train_setup=train_setup)\n",
    "\n",
    "    def _new(self, items, **kwargs): return super()._new(items, tfms=self.tfms, do_setup=False, **kwargs)\n",
    "    def subset(self, i): return self._new(self._get(self.filts[i]), filt=i)\n",
    "    def _after_item(self, o): return self.tfms(o)\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: {self.items}\\ntfms - {self.tfms.fs}\"\n",
    "    def __iter__(self): return (self[i] for i in range(len(self)))\n",
    "    def show(self, o, **kwargs): return self.tfms.show(o, **kwargs)\n",
    "    def decode(self, x, **kwargs): return self.tfms.decode(x, **kwargs)\n",
    "    def __call__(self, x, **kwargs): return self.tfms.__call__(x, **kwargs)\n",
    "    def setup(self, train_setup=True): self.tfms.setup(getattr(self,'train',self) if train_setup else self)\n",
    "    @property\n",
    "    def default(self): return self.tfms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        res = super().__getitem__(idx)\n",
    "        if self._after_item is None: return res\n",
    "        return self._after_item(res) if is_indexer(idx) else res.map(self._after_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(TfmdList,\n",
    "         setup=\"Transform setup with self\",\n",
    "         decode=\"From `Pipeline\",\n",
    "         show=\"From `Pipeline\",\n",
    "         subset=\"New `TfmdList` that only includes subset `i`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def decode_at(o, idx):\n",
    "    \"Decoded item at `idx`\"\n",
    "    return o.decode(o[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def show_at(o, idx, **kwargs):\n",
    "    \"Show item at `idx`\",\n",
    "    return o.show(o[idx], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `TfmdList` combines a collection of object with a `Pipeline`. `tfms` can either be a `Pipeline` or a list of transforms, in which case, it will wrap them in a `Pipeline`. `use_list` is passed along to `L` with the `items`, `as_item` and `filt` are passed to each transform of the `Pipeline`. `do_setup` indicates if the `Pipeline.setup` method should be called during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntFloatTfm(Transform):\n",
    "    def encodes(self, x):  return Int(x)\n",
    "    def decodes(self, x):  return Float(x)\n",
    "    foo=1\n",
    "\n",
    "int_tfm=IntFloatTfm()\n",
    "\n",
    "def neg(x): return -x\n",
    "neg_tfm = Transform(neg, neg)\n",
    "\n",
    "class B(Transform):\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "add1 = B()\n",
    "add1.filt = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdList: [1.0, 2.0, 3.0]\n",
       "tfms - (#2) [Transform: True {'object': 'neg'} {'object': 'neg'},IntFloatTfm: True {'object': 'encodes'} {'object': 'decodes'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl = TfmdList([1.,2.,3.], [neg_tfm, int_tfm], filts=[[0,2],[1]])\n",
    "t = tl[1]\n",
    "test_eq_type(t, Int(-2))\n",
    "test_eq(decode_at(tl, 1), 2)\n",
    "test_eq_type(tl.decode(t), Float(2.0))\n",
    "test_stdout(lambda: show_at(tl, 2), '-3')\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TfmdList([1.,2.,3.], [neg_tfm, int_tfm, add1], filts=[[0,2],[1]])\n",
    "test_eq(tl[0], -1)\n",
    "test_eq(tl[1], -2)\n",
    "test_eq(tl.valid[0], -1) #add1 is only applied on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = tl.subset(0)\n",
    "test_eq(p2, [-1,-3])\n",
    "test_eq(map(type, p2), (Int,Int))\n",
    "test_eq(tl[tensor(1)], tl[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(a=[1,2,3],b=[2,3,4]))\n",
    "tl = TfmdList(df, lambda o: o.a, filts=[[0],[1,2]])\n",
    "test_eq(tl[1,2], [2,3])\n",
    "p2 = tl.subset(1)\n",
    "test_eq(p2, [2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(Transform):\n",
    "    def __init__(self):   self.a = 2\n",
    "    def encodes(self, x): return x+self.a\n",
    "    def decodes(self, x): return x-self.a\n",
    "    def setups(self, items): self.a = tensor(items).float().mean().item()\n",
    "\n",
    "tl1 = TfmdList([1,2,3,4], B())\n",
    "test_eq(tl1.tfms[0].a, 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfilts = [tensor([0,2]), [1,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TfmdList(range(5), tfms=[None], filts=tfilts)\n",
    "test_eq(len(tl.filts), 2)\n",
    "test_eq(tl.subset(0), [0,2])\n",
    "test_eq(tl.train, [0,2])       # Subset 0 is aliased to `train`\n",
    "test_eq(tl.subset(1), [1,3,4])\n",
    "test_eq(tl.valid, [1,3,4])     # Subset 1 is aliased to `valid`\n",
    "test_eq(tl.valid[2], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can use `TfmdList.setup` to implement a simple category list, getting labels from a mock file list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Cat(Transform):\n",
    "    order = 1\n",
    "    def encodes(self, o):    return int(self.o2i[o])\n",
    "    def decodes(self, o):    return Str(self.vocab[o])\n",
    "    def setups(self, items): self.vocab,self.o2i = uniqueify(L(items), sort=True, bidir=True)\n",
    "\n",
    "def _lbl(o):  return Str(o.split('_')[0])\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tcat = _Cat()\n",
    "# Check that tfms are sorted by `order`\n",
    "tl = TfmdList(test_fns, [tcat,_lbl])\n",
    "\n",
    "exp_voc = ['cat','dog']\n",
    "test_eq(tcat.vocab, exp_voc)\n",
    "test_eq(tl.tfms.vocab, exp_voc)\n",
    "test_eq(tl.vocab, exp_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdList: ['dog_0.jpg', 'cat_0.jpg', 'cat_2.jpg', 'cat_1.jpg', 'dog_1.jpg']\n",
       "tfms - (#2) [Transform: True {'object': '_lbl'} {},_Cat: True {'object': 'encodes'} {'object': 'decodes'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(tl, (1,0,0,0,1))\n",
    "t = L(tl)\n",
    "test_eq(t, [1,0,0,0,1])\n",
    "test_eq(tl[-1], 1)\n",
    "test_eq(tl[0,1], (1,0))\n",
    "test_eq([tl.decode(o) for o in t], ('dog','cat','cat','cat','dog'))\n",
    "test_stdout(lambda:show_at(tl, 0), \"dog\")\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg','kid_05.jpg']\n",
    "tcat = _Cat()\n",
    "tl = TfmdList(test_fns, [tcat,_lbl], filts=[[0,1,2,3,4], [5]])\n",
    "#Check only the training set is taken into account for setup\n",
    "test_eq(tcat.vocab, ['cat','dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = NegTfm(filt=1)\n",
    "tds = TfmdList(start, A())\n",
    "tdl = TfmdDL(tds, after_batch=tfm, bs=4)\n",
    "x = tdl.one_batch()\n",
    "test_eq(x, torch.arange(4))\n",
    "tds.filt = 1\n",
    "x = tdl.one_batch()\n",
    "test_eq(x, -torch.arange(4))\n",
    "tds.filt = 0\n",
    "x = tdl.one_batch()\n",
    "test_eq(x, torch.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = TfmdList(start, A())\n",
    "tdl = TfmdDL(tds, after_batch=NegTfm(), bs=4)\n",
    "test_eq(tdl.dataset[0], start[0])\n",
    "test_eq(len(tdl), (len(tds)-1)//4+1)\n",
    "test_eq(tdl.bs, 4)\n",
    "test_stdout(tdl.show_batch, '0\\n1\\n2\\n3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TfmdList.subset\" class=\"doc_header\"><code>TfmdList.subset</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L13\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.subset</code>(**`i`**)\n",
       "\n",
       "New [`TfmdList`](/data.core.html#TfmdList) that only includes subset `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSource -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "@delegates(TfmdList)\n",
    "class DataSource(FilteredBase):\n",
    "    \"A dataset that creates a tuple from each `tfms`, passed thru `ds_tfms`\"\n",
    "    def __init__(self, items=None, tfms=None, tls=None, **kwargs):\n",
    "        self.tls = L(tls if tls else [TfmdList(items, t, **kwargs) for t in L(ifnone(tfms,[None]))])\n",
    "\n",
    "    def __getitem__(self, it):\n",
    "        res = tuple([tl[it] for tl in self.tls])\n",
    "        return res if is_indexer(it) else list(zip(*res))\n",
    "    \n",
    "    def __getattr__(self,k): return gather_attrs(self, k, 'tls')\n",
    "    def __len__(self): return len(self.tls[0])\n",
    "    def __iter__(self): return (self[i] for i in range(len(self)))\n",
    "    def __repr__(self): return coll_repr(self)\n",
    "    def decode(self, o): return tuple(tl.decode(o_) for o_,tl in zip(o,self.tls))\n",
    "    def subset(self, i): return type(self)(tls=L(tl.subset(i) for tl in self.tls))\n",
    "    def _new(self, items, *args, **kwargs): return super()._new(items, tfms=self.tfms, do_setup=False, **kwargs)\n",
    "    @property\n",
    "    def filts(self): return self.tls[0].filts\n",
    "    @property\n",
    "    def filt(self): return self.tls[0].tfms.filt\n",
    "    \n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        for o_,tl in zip(o,self.tls): ctx = tl.show(o_, ctx=ctx, **kwargs)\n",
    "        return ctx\n",
    "\n",
    "    _docs=dict(\n",
    "        decode=\"Compose `decode` of all `tuple_tfms` then all `tfms` on `i`\",\n",
    "        show=\"Show item `o` in `ctx`\",\n",
    "        databunch=\"Get a `DataBunch`\",\n",
    "        subset=\"New `DataSource` that only includes subset `i`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataSource` creates a tuple from `items` (typically input,target) by applying each list of `Transform` (or `Pipeline`) in `tfms` to them. Note that if `tfms` contains only one list of `tfms`, the items given by `DataSource` will be tuples of one element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "dsrc = DataSource(items, [[neg_tfm,int_tfm]])\n",
    "test_eq(dsrc[0], (-1,))\n",
    "test_eq(dsrc[0,1,2], [(-1,),(-2,),(-3,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(Transform):\n",
    "    def encodes(self, o): return (o-self.m)/self.s\n",
    "    def decodes(self, o): return (o*self.s)+self.m\n",
    "    def setups(self, items):\n",
    "        its = tensor(items).float()\n",
    "        self.m,self.s = its.mean(),its.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "nrm = Norm()\n",
    "dsrc = DataSource(items, [[neg_tfm,int_tfm], [neg_tfm,nrm]])\n",
    "\n",
    "x,y = zip(*dsrc)\n",
    "test_close(tensor(y).mean(), 0)\n",
    "test_close(tensor(y).std(), 1)\n",
    "test_eq(x, (-1,-2,-3,-4,))\n",
    "test_eq(nrm.m, -2.5)\n",
    "test_stdout(lambda:show_at(dsrc, 1), '-2')\n",
    "\n",
    "test_eq(dsrc.m, nrm.m)\n",
    "test_eq(dsrc.norm.m, nrm.m)\n",
    "test_eq(dsrc.train.norm.m, nrm.m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check filtering is properly applied\n",
    "class B(Transform):\n",
    "    def encodes(self, x)->None:  return int(x+1)\n",
    "    def decodes(self, x):        return Int(x-1)\n",
    "add1 = B(filt=1)\n",
    "\n",
    "dsrc = DataSource(items, [neg_tfm, [neg_tfm,int_tfm,add1]], filts=[[3],[0,1,2]])\n",
    "test_eq(dsrc[1], [-2,-2])\n",
    "test_eq(dsrc.valid[1], [-2,-1])\n",
    "test_eq(dsrc.valid[[1,1]], [[-2,-1], [-2,-1]])\n",
    "test_eq(dsrc.train[0], [-4,-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test setup works with train attribute\n",
    "def _lbl(o): return o.split('_')[0]\n",
    "\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','kid_1.jpg']\n",
    "tcat = _Cat()\n",
    "dsrc = DataSource(test_fns, [[tcat,_lbl]], filts=[[0,1,2], [3,4]])\n",
    "test_eq(tcat.vocab, ['cat','dog'])\n",
    "test_eq(dsrc.train, [(1,),(0,),(0,)])\n",
    "test_eq(dsrc.valid[0], (0,))\n",
    "test_stdout(lambda: show_at(dsrc.train, 0), \"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = [0,1,2,3,4]\n",
    "dsrc = DataSource(inp, tfms=[None])\n",
    "\n",
    "test_eq(*dsrc[2], 2)          # Retrieve one item (subset 0 is the default)\n",
    "test_eq(dsrc[1,2], [(1,),(2,)])    # Retrieve two items by index\n",
    "mask = [True,False,False,True,False]\n",
    "test_eq(dsrc[mask], [(0,),(3,)])   # Retrieve two items by mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = pd.DataFrame(dict(a=[5,1,2,3,4]))\n",
    "dsrc = DataSource(inp, tfms=attrgetter('a')).subset(0)\n",
    "test_eq(*dsrc[2], 2)          # Retrieve one item (subset 0 is the default)\n",
    "test_eq(dsrc[1,2], [(1,),(2,)])    # Retrieve two items by index\n",
    "mask = [True,False,False,True,False]\n",
    "test_eq(dsrc[mask], [(5,),(3,)])   # Retrieve two items by mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [(0,),(1,),(2,),(3,),(4,)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filts can be indices\n",
    "dsrc = DataSource(range(5), tfms=[None], filts=[tensor([0,2]), [1,3,4]])\n",
    "\n",
    "test_eq(dsrc.subset(0), [(0,),(2,)])\n",
    "test_eq(dsrc.train, [(0,),(2,)])       # Subset 0 is aliased to `train`\n",
    "test_eq(dsrc.subset(1), [(1,),(3,),(4,)])\n",
    "test_eq(dsrc.valid, [(1,),(3,),(4,)])     # Subset 1 is aliased to `valid`\n",
    "test_eq(*dsrc.valid[2], 4)\n",
    "#assert '[(1,),(3,),(4,)]' in str(dsrc) and '[(0,),(2,)]' in str(dsrc)\n",
    "dsrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filts can be boolean masks (they don't have to cover all items, but must be disjoint)\n",
    "filts = [[False,True,True,False,True], [True,False,False,False,False]]\n",
    "dsrc = DataSource(range(5), tfms=[None], filts=filts)\n",
    "\n",
    "test_eq(dsrc.train, [(1,),(2,),(4,)])\n",
    "test_eq(dsrc.valid, [(0,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply transforms to all items\n",
    "tfm = [[lambda x: x*2,lambda x: x+1]]\n",
    "filts = [[1,2],[0,3,4]]\n",
    "dsrc = DataSource(range(5), tfm, filts=filts)\n",
    "test_eq(dsrc.train,[(3,),(5,)])\n",
    "test_eq(dsrc.valid,[(1,),(7,),(9,)])\n",
    "test_eq(dsrc.train[False,True], [(5,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only transform subset 1\n",
    "class _Tfm(Transform):\n",
    "    filt=1\n",
    "    def encodes(self, x): return x*2\n",
    "    def decodes(self, x): return Str(x//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [(0,),(1,),(2,),(3,),(4,)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc = DataSource(range(5), [_Tfm()], filts=[[1,2],[0,3,4]])\n",
    "test_eq(dsrc.train,[(1,),(2,)])\n",
    "test_eq(dsrc.valid,[(0,),(6,),(8,)])\n",
    "test_eq(dsrc.train[False,True], [(2,)])\n",
    "dsrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test DataSource pickles\n",
    "dsrc1 = pickle.loads(pickle.dumps(dsrc))\n",
    "test_eq(dsrc.train, dsrc1.train)\n",
    "test_eq(dsrc.valid, dsrc1.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc = DataSource(range(5), [_Tfm(),noop], filts=[[1,2],[0,3,4]])\n",
    "test_eq(dsrc.train,[(1,1),(2,2)])\n",
    "test_eq(dsrc.valid,[(0,0),(6,3),(8,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.arange(0,50)\n",
    "tds = DataSource(start, [A()])\n",
    "tdl = TfmdDL(tds, after_item=NegTfm(), bs=4)\n",
    "b = tdl.one_batch()\n",
    "test_eq(tdl.decode_batch(b), ((0,),(1,),(2,),(3,)))\n",
    "test_stdout(tdl.show_batch, \"0\\n1\\n2\\n3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only transform subset 1\n",
    "class _Tfm(Transform):\n",
    "    filt=1\n",
    "    def encodes(self, x): return x*2\n",
    "\n",
    "dsrc = DataSource(range(8), [None], filts=[[1,2,5,7],[0,3,4,6]])\n",
    "dbch = dsrc.databunch(bs=4, after_batch=_Tfm(), shuffle_train=False)\n",
    "test_eq(dbch.train_dl, [(tensor([1,2,5, 7]),)])\n",
    "test_eq(dbch.valid_dl, [(tensor([0,6,8,12]),)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "dsrc = DataSource(items, [[neg_tfm,int_tfm]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DataSource.decode\" class=\"doc_header\"><code>DataSource.decode</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L17\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataSource.decode</code>(**`o`**)\n",
       "\n",
       "Compose `decode` of all `tuple_tfms` then all `tfms` on `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataSource.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(*dsrc[0], -1)\n",
    "test_eq(*dsrc.decode((-1,)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DataSource.show\" class=\"doc_header\"><code>DataSource.show</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L25\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataSource.show</code>(**`o`**, **`ctx`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show item `o` in `ctx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataSource.show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda:dsrc.show(dsrc[1]), '-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add test set for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only transform subset 1\n",
    "class _Tfm1(Transform):\n",
    "    filt=0\n",
    "    def encodes(self, x): return x*3\n",
    "\n",
    "dsrc = DataSource(range(8), [[_Tfm(),_Tfm1()]], filts=[[1,2,5,7],[0,3,4,6]])\n",
    "test_eq(dsrc.train, [(3,),(6,),(15,),(21,)])\n",
    "test_eq(dsrc.valid, [(0,),(6,),(8,),(12,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def test_set(dsrc, test_items):\n",
    "    \"Create a test set from `test_items` using validation transforms of `dsrc`\"\n",
    "    test_tl = dsrc.tls[0]._new(test_items, filt=1)\n",
    "    return DataSource(tls=[test_tl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Tfm1(Transform):\n",
    "    filt=0\n",
    "    def encodes(self, x): return x*3\n",
    "\n",
    "dsrc = DataSource(range(8), [[_Tfm(),_Tfm1()]], filts=[[1,2,5,7],[0,3,4,6]])\n",
    "test_eq(dsrc.train, [(3,),(6,),(15,),(21,)])\n",
    "test_eq(dsrc.valid, [(0,),(6,),(8,),(12,)])\n",
    "\n",
    "#Tranform of the validation set are applied\n",
    "tst = test_set(dsrc, [1,2,3])\n",
    "test_eq(tst, [(2,),(4,),(6,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def test_dl(dbunch, test_items):\n",
    "    \"Create a test dataloader `test_items` using validation transforms of `dbunch`\"\n",
    "    test_ds = test_set(dbunch.valid_ds, test_items)\n",
    "    return dbunch.valid_dl.new(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbunch = dsrc.databunch(bs=4)\n",
    "tst_dl = test_dl(dbunch, [2,3,4,5])\n",
    "test_eq(list(tst_dl), [(tensor([ 4,  6,  8, 10]),)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 01a_torch_core.ipynb.\n",
      "Converted 02_script.ipynb.\n",
      "Converted 03_dataloader.ipynb.\n",
      "Converted 04_transform.ipynb.\n",
      "Converted 05_data_core.ipynb.\n",
      "Converted 06_data_transforms.ipynb.\n",
      "Converted 07_vision_core.ipynb.\n",
      "Converted 08_pets_tutorial.ipynb.\n",
      "Converted 09_vision_augment.ipynb.\n",
      "Converted 11_layers.ipynb.\n",
      "Converted 11a_vision_models_xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 14_callback_schedule.ipynb.\n",
      "Converted 15_callback_hook.ipynb.\n",
      "Converted 16_callback_progress.ipynb.\n",
      "Converted 17_callback_tracker.ipynb.\n",
      "Converted 18_callback_fp16.ipynb.\n",
      "Converted 19_callback_mixup.ipynb.\n",
      "Converted 20_metrics.ipynb.\n",
      "Converted 21_tutorial_imagenette.ipynb.\n",
      "Converted 22_vision_learner.ipynb.\n",
      "Converted 23_tutorial_transfer_learning.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 31_text_data.ipynb.\n",
      "Converted 32_text_models_awdlstm.ipynb.\n",
      "Converted 33_text_models_core.ipynb.\n",
      "Converted 34_callback_rnn.ipynb.\n",
      "Converted 35_tutorial_wikitext.ipynb.\n",
      "Converted 36_text_models_qrnn.ipynb.\n",
      "Converted 37_text_learner.ipynb.\n",
      "Converted 38_tutorial_ulmfit.ipynb.\n",
      "Converted 40_tabular_core.ipynb.\n",
      "Converted 41_tabular_model.ipynb.\n",
      "Converted 42_tabular_rapids.ipynb.\n",
      "Converted 50_data_block.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_utils_test.ipynb.\n",
      "Converted 96_data_external.ipynb.\n",
      "Converted notebook2jekyll.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
